{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5497,
     "status": "ok",
     "timestamp": 1669682859128,
     "user": {
      "displayName": "Ximena González",
      "userId": "01616957970933617687"
     },
     "user_tz": 480
    },
    "id": "6R7Q5sTeP2Iw",
    "outputId": "d66903b4-279a-4728-cc5e-f78b8972e688"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/UNI/COLABS\n"
     ]
    }
   ],
   "source": [
    "%cd # Cambiar por la dirección donde esta la carpeta\n",
    "\n",
    "# importar todas las librerias necesarias\n",
    "\n",
    "from keras.layers import Conv2D, Conv2DTranspose, UpSampling2D\n",
    "from keras.layers import Activation, Dense, Dropout, Flatten, InputLayer\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import array_to_img, img_to_array, load_img\n",
    "from skimage.color import rgb2lab, lab2rgb, rgb2gray\n",
    "from skimage.io import imsave\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from PIL import Image, ImageOps\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from colorization.colorizers import *\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XdfwEXrm8mi2"
   },
   "outputs": [],
   "source": [
    "X = [] # Crear archivo donde esten todas las imágenes como matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rko156uKQoIx"
   },
   "outputs": [],
   "source": [
    "for filename in os.listdir('DATA/natural_color/color'): # Por cada imagen de color\n",
    "  X.append(img_to_array(load_img('DATA/natural_color/color/'+filename))) # Se agrega como matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1669621407382,
     "user": {
      "displayName": "Ximena González",
      "userId": "01616957970933617687"
     },
     "user_tz": 480
    },
    "id": "aKG-maDFyHNl",
    "outputId": "3f7e406c-6f97-4688-cf5f-6edcda3ee816"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "688\n"
     ]
    }
   ],
   "source": [
    "print(len(X)) # Imprimir cantidad de imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u7JzxR1_Qsg3"
   },
   "outputs": [],
   "source": [
    "X = np.array(X, dtype=float) # Guardar como arreglo de numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nM4kr0q_QvWw"
   },
   "outputs": [],
   "source": [
    "split = int(0.95*len(X)) # Dividir el 95% para entrenamiento y 5% para pruebas\n",
    "Xtrain = X[:split] # Todas hasta split\n",
    "Xtrain = 1.0/255*Xtrain # Normalizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1669621408161,
     "user": {
      "displayName": "Ximena González",
      "userId": "01616957970933617687"
     },
     "user_tz": 480
    },
    "id": "9ozgK3ISHYe7",
    "outputId": "5a9673e2-7bab-41dd-9fd8-4f4c8a9f716f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(653, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "print(Xtrain.shape) # 653 imagenes de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pqzj1u-KHeZN"
   },
   "outputs": [],
   "source": [
    "model = Sequential() # Instanciar modelo de keras secuencial para que se sumen los modelos\n",
    "model.add(InputLayer(input_shape=(256, 256, 1))) # Ajustar la entrada para aceptar una matriz de 256 * 256 pixeles\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same')) # Todos los bloques convolucionales\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same', strides=2))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same', strides=2))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same', strides=2))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(2, (3, 3), activation='tanh', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.compile(optimizer='rmsprop', loss='mse') # Compilar el modelo y establecer las métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U0HwT-3zHiUm"
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        rotation_range=20,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# Instancia de ImageDataGenerator que genera grupos de tensor de imágenes con aumentación de datos\n",
    "\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p_5fah4eHnDO"
   },
   "outputs": [],
   "source": [
    "def image_a_b_gen(batch_size):  \n",
    "    for batch in datagen.flow(Xtrain, batch_size=batch_size): # Generar los batches\n",
    "        lab_batch = rgb2lab(batch) # Pasar de rgb a lab\n",
    "        X_batch = lab_batch[:,:,:,0] # Separar l\n",
    "        Y_batch = lab_batch[:,:,:,1:] / 128 # Separar ab\n",
    "        yield (X_batch.reshape(X_batch.shape+(1,)), Y_batch) # Reconfigurar la matriz para tener el tamaño de la entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2152596,
     "status": "ok",
     "timestamp": 1669542023341,
     "user": {
      "displayName": "Ximena González",
      "userId": "01616957970933617687"
     },
     "user_tz": 480
    },
    "id": "ohfK9W8EHoVq",
    "outputId": "e8abbb4b-124b-4859-f2c1-9072494bad3f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "950/950 [==============================] - 227s 227ms/step - loss: 0.5996\n",
      "Epoch 2/10\n",
      "950/950 [==============================] - 216s 227ms/step - loss: 0.0220\n",
      "Epoch 3/10\n",
      "950/950 [==============================] - 216s 227ms/step - loss: 0.0146\n",
      "Epoch 4/10\n",
      "950/950 [==============================] - 215s 226ms/step - loss: 0.0123\n",
      "Epoch 5/10\n",
      "950/950 [==============================] - 215s 226ms/step - loss: 0.0105\n",
      "Epoch 6/10\n",
      "950/950 [==============================] - 214s 226ms/step - loss: 0.0094\n",
      "Epoch 7/10\n",
      "950/950 [==============================] - 215s 227ms/step - loss: 0.0088\n",
      "Epoch 8/10\n",
      "950/950 [==============================] - 214s 225ms/step - loss: 0.0078\n",
      "Epoch 9/10\n",
      "950/950 [==============================] - 212s 223ms/step - loss: 0.0073\n",
      "Epoch 10/10\n",
      "950/950 [==============================] - 207s 218ms/step - loss: 0.0064\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7308af2750>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorboard = TensorBoard(log_dir=\"AM-PROY-2/Full-version/first_run\") # Instanciar TensorBoard para visualización\n",
    "model.fit_generator(image_a_b_gen(batch_size), callbacks=[tensorboard], epochs=10, steps_per_epoch=950) # Entrenar el modelo con los batches de imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uHBFd9pHBusf"
   },
   "outputs": [],
   "source": [
    "# Si se entrenó, se corre esta celda para guardar el modelo\n",
    "\n",
    "model_json = model.to_json() # json guarda la estructura de los bloques convolusionales\n",
    "with open(\"AM-PROY-2/Beta-version/model2.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(\"AM-PROY-2/Beta-version/model_3.h5\") # Guarda los pesos entrenados de las neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QEi_7_Hg1a85"
   },
   "outputs": [],
   "source": [
    "# Si se quiere recuperar el modelo sin entrenar, se corre esta celda\n",
    "\n",
    "json_file = open(\"AM-PROY-2/Beta-version/model2.json\", 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json) # Cargar la estructura de los bloques convolucionales\n",
    "\n",
    "model.load_weights(\"AM-PROY-2/Beta-version/model_3.h5\") # Cargar los pesos del modelo\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='mse') # Compilar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QP7hn_xsB3yS"
   },
   "outputs": [],
   "source": [
    "Xtest = rgb2lab(1.0/255*X[split:])[:,:,:,0] # Imagenes de prueba en lab separados solo l\n",
    "Xtest = Xtest.reshape(Xtest.shape+(1,)) # Reconfigurar para que tenga el mismo tamaño que la entrada de la red neuronal\n",
    "Ytest = rgb2lab(1.0/255*X[split:])[:,:,:,1:] # Imagenes de prueba en lab, solamente ab\n",
    "Ytest = Ytest / 128 # Dividir entre 128 para normalizar y que sea a y b de 0 a 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1669621416900,
     "user": {
      "displayName": "Ximena González",
      "userId": "01616957970933617687"
     },
     "user_tz": 480
    },
    "id": "7VmzGZ2BeCmL",
    "outputId": "23bfabbd-fb59-4fcf-98da-d6ed46e0fdd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n",
      "35\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(Xtest))\n",
    "print(len(Ytest))\n",
    "type(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6207,
     "status": "ok",
     "timestamp": 1669621425626,
     "user": {
      "displayName": "Ximena González",
      "userId": "01616957970933617687"
     },
     "user_tz": 480
    },
    "id": "irNe_p3netZF",
    "outputId": "97828db6-122a-4c55-bde6-485333301661"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 3s 620ms/step - loss: 0.0032\n",
      "0.003204912645742297\n",
      "35/35 [==============================] - 3s 90ms/step - loss: 0.0032\n",
      "0.003204912878572941\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10 # MSE del modelo en Keras\n",
    "\n",
    "print(model.evaluate(Xtest, Ytest, batch_size=batch_size))\n",
    "print(model.evaluate(Xtest, Ytest, batch_size = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1224,
     "status": "ok",
     "timestamp": 1669622011559,
     "user": {
      "displayName": "Ximena González",
      "userId": "01616957970933617687"
     },
     "user_tz": 480
    },
    "id": "ClgHmZAHCCbx",
    "outputId": "839d2023-c45e-484e-c4e3-e117d70b8427"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    }
   ],
   "source": [
    "color_me = [] # Arreglo vacío para guardar las matrices de las imágenes\n",
    "for filename in os.listdir('DATA/natural_color/gray'): # Cargar las imágenes\n",
    "  color_me.append(img_to_array(load_img('DATA/natural_color/gray/'+filename)))\n",
    "\n",
    "color_me = X[split:] # Reescribir para que sean las mismas que pruebas\n",
    "print(len(color_me))\n",
    "color_me = np.array(color_me, dtype=float) # Modificar a flotantes por si hay enteros\n",
    "color_me = rgb2lab(1.0/255*color_me)[:,:,:,0] # Cambiar a lab, pero solo obtener l\n",
    "color_me = color_me.reshape(color_me.shape+(1,)) # Reconfigurar para que tenga el tamaño de la entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3237,
     "status": "ok",
     "timestamp": 1669622020337,
     "user": {
      "displayName": "Ximena González",
      "userId": "01616957970933617687"
     },
     "user_tz": 480
    },
    "id": "IUfSdBfxCcwM",
    "outputId": "16fe02da-22f7-4206-d40c-927a9bcae368"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 3s 224ms/step\n"
     ]
    }
   ],
   "source": [
    "output = model.predict(color_me) # Predecir por cada imágen en el arreglo\n",
    "output = output * 128 # Multiplicar por 128 para regresar de la normalización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5347,
     "status": "ok",
     "timestamp": 1669622229634,
     "user": {
      "displayName": "Ximena González",
      "userId": "01616957970933617687"
     },
     "user_tz": 480
    },
    "id": "SRwGSjHFCga5",
    "outputId": "44921ece-57ed-47cc-af88-52716b83f43a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/usr/local/lib/python3.7/dist-packages/skimage/color/colorconv.py:1109: UserWarning: Color data out of range: Z < 0 in 4 pixels\n",
      "  return xyz2rgb(lab2xyz(lab, illuminant, observer))\n",
      "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/usr/local/lib/python3.7/dist-packages/skimage/color/colorconv.py:1109: UserWarning: Color data out of range: Z < 0 in 19 pixels\n",
      "  return xyz2rgb(lab2xyz(lab, illuminant, observer))\n",
      "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/usr/local/lib/python3.7/dist-packages/skimage/color/colorconv.py:1109: UserWarning: Color data out of range: Z < 0 in 2 pixels\n",
      "  return xyz2rgb(lab2xyz(lab, illuminant, observer))\n",
      "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/usr/local/lib/python3.7/dist-packages/skimage/color/colorconv.py:1109: UserWarning: Color data out of range: Z < 0 in 12 pixels\n",
      "  return xyz2rgb(lab2xyz(lab, illuminant, observer))\n",
      "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/usr/local/lib/python3.7/dist-packages/skimage/color/colorconv.py:1109: UserWarning: Color data out of range: Z < 0 in 9 pixels\n",
      "  return xyz2rgb(lab2xyz(lab, illuminant, observer))\n",
      "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/usr/local/lib/python3.7/dist-packages/skimage/color/colorconv.py:1109: UserWarning: Color data out of range: Z < 0 in 75 pixels\n",
      "  return xyz2rgb(lab2xyz(lab, illuminant, observer))\n",
      "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/usr/local/lib/python3.7/dist-packages/skimage/color/colorconv.py:1109: UserWarning: Color data out of range: Z < 0 in 6 pixels\n",
      "  return xyz2rgb(lab2xyz(lab, illuminant, observer))\n",
      "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/usr/local/lib/python3.7/dist-packages/skimage/color/colorconv.py:1109: UserWarning: Color data out of range: Z < 0 in 1 pixels\n",
      "  return xyz2rgb(lab2xyz(lab, illuminant, observer))\n",
      "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/usr/local/lib/python3.7/dist-packages/skimage/color/colorconv.py:1109: UserWarning: Color data out of range: Z < 0 in 5 pixels\n",
      "  return xyz2rgb(lab2xyz(lab, illuminant, observer))\n",
      "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(output)): # Por cada imágen que regrese el modelo\n",
    "  cur = np.zeros((256, 256, 3)) # Arreglo vacio para juntar la entrada con el output del modelo\n",
    "  cur[:,:,0] = color_me[i][:,:,0]\n",
    "  cur[:,:,1:] = output[i]\n",
    "  imsave(f\"pred/Testing_{i}.png\", lab2rgb(cur)) # Guardar como imagen el resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86,
     "referenced_widgets": [
      "c75ee4e76d104b13b3d0ae98b6638890",
      "472ecf1f6c494e55aa0fe8739555a40b",
      "3f5bfdbf55594af8a2ca09371baa9d09",
      "33b04a17fd5c4bd69523bfa90605ede5",
      "737ee5c5c22c40298bf85c8386df7e68",
      "9665b1654eac4130821c43b878a058c1",
      "c3754762a8c24b898af8da17108b3d0a",
      "84203aa2f56b422d858d499f3b9423f1",
      "300e6a88fa394c1aac3d2dbcb0d91196",
      "05a094b6c9874ee9b3e5da3375f79255",
      "5e7750a0784c4e439829374c8b2ab92d"
     ]
    },
    "executionInfo": {
     "elapsed": 3569,
     "status": "ok",
     "timestamp": 1669682871965,
     "user": {
      "displayName": "Ximena González",
      "userId": "01616957970933617687"
     },
     "user_tz": 480
    },
    "id": "O89_-sGZ5hVh",
    "outputId": "9d812f14-8b96-478b-e9e9-131a5ba46a2e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://colorizers.s3.us-east-2.amazonaws.com/siggraph17-df00044c.pth\" to /root/.cache/torch/hub/checkpoints/siggraph17-df00044c.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c75ee4e76d104b13b3d0ae98b6638890",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/130M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colorizer_siggraph17 = siggraph17(pretrained=True).eval() # Cargar el modelo entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "khwKOWBP6wLZ"
   },
   "outputs": [],
   "source": [
    "Y = np.zeros((35, 256, 256, 3)) # Arreglo vacio que va a guardar las imágenes de prueba\n",
    "\n",
    "for i in range(len(X[split:])): # Por cada imagen de prueba\n",
    "  x = X[split:][i] # Guardar la imagen\n",
    "  img = array_to_img(x) # Transformarla a matriz\n",
    "  img.save(f'original/Testing_{i}.png') # Guardar la imagen original\n",
    "  img = ImageOps.grayscale(img) # Transformarla a escala de grises\n",
    "  img.save(f'bw/Testing_{i}.png') # Guardar la imágen en escala de grises\n",
    "  img = load_img(f'bw/Testing_{i}.png') # Cargar la imagen\n",
    "\n",
    "  # Pasarla por el colorizador siggraph\n",
    "  (tens_l_orig, tens_l_rs) = preprocess_img(img, HW=(256,256))\n",
    "  img_bw = postprocess_tens(tens_l_orig, torch.cat((0*tens_l_orig,0*tens_l_orig),dim=1))\n",
    "  out_img_siggraph17 = postprocess_tens(tens_l_orig, colorizer_siggraph17(tens_l_rs).cpu())\n",
    "  # out_img_siggraph17 matriz que predice el modelo de siggraph\n",
    "\n",
    "  plt.imsave(f'algorithm_siggraph/Testing_{i}.png', out_img_siggraph17) # Guardar la predicción como imagen\n",
    "  Y[i] = out_img_siggraph17 # Guardar el resultado como matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 291,
     "status": "ok",
     "timestamp": 1669682948875,
     "user": {
      "displayName": "Ximena González",
      "userId": "01616957970933617687"
     },
     "user_tz": 480
    },
    "id": "MEHDzvWIP8nu"
   },
   "outputs": [],
   "source": [
    "def rgb_ab( tup ):\n",
    "  if type(tup) == int: # En caso de que la función regrese getpixel regrese un \n",
    "                       # solo número, se transforma en tupla rgb con ese mismo \n",
    "                       # valor en los 3\n",
    "    tup = (tup, tup, tup)\n",
    "  # Función que transforma rgb a ab con las fórmulas del paper\n",
    "  # Acepta una tupla con 3 valores rgb y regresa una tupla de 2 (a,b)\n",
    "  I = (tup[0] + tup[1] + tup[2])/3\n",
    "  if (I == 0):\n",
    "    return (0,0)\n",
    "  a = (tup[2]/I) - ((tup[0] + tup[1])/(2*I))\n",
    "  b = (tup[0] - tup[1])/I\n",
    "  return (a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 38048,
     "status": "ok",
     "timestamp": 1669682988690,
     "user": {
      "displayName": "Ximena González",
      "userId": "01616957970933617687"
     },
     "user_tz": 480
    },
    "id": "4iTq1aMtNhIR",
    "outputId": "f5296209-25d0-434c-be05-87ac8b68d517"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE promedio por imagen entre color y nuestras predicciones\n",
      "a 0.06090106495983092\n",
      "b 0.011591519796284158\n"
     ]
    }
   ],
   "source": [
    "# importar nombres de las imágenes de cada directorio\n",
    "images_bw = os.listdir('bw')\n",
    "images_sig = os.listdir('algorithm_siggraph')\n",
    "images_color = os.listdir('original')\n",
    "images_pred = os.listdir('pred')\n",
    "\n",
    "# Arreglo que contendrá el MSE de cada imágen\n",
    "MSE_a = []\n",
    "MSE_b = []\n",
    "\n",
    "for i in range(len(images_color)): # Por cada imagen\n",
    "  img_color = Image.open('original/' + images_color[i]) # Abrir imagen a color\n",
    "  img_pred = Image.open('pred/' + images_pred[i]) # Abrir predicción\n",
    "\n",
    "  # Se guardan los valores de los pixeles \n",
    "  Y_pred_a = []\n",
    "  Y_pred_b = []\n",
    "  Y_true_a = []\n",
    "  Y_true_b = []\n",
    "\n",
    "  for w in range(img_color.size[0]):\n",
    "    for h in range(img_color.size[1]):\n",
    "      # Por cada pixel en altura y ancho de la imagen\n",
    "        # Regresar el valor a,b del pixel y agregarlo a su respectiva lista entre las imagenes original y la predicción:\n",
    "        Y_pred_a.append(rgb_ab(img_pred.getpixel((w,h)))[0])\n",
    "        Y_pred_b.append(rgb_ab(img_pred.getpixel((w,h)))[1])  \n",
    "        Y_true_a.append(rgb_ab(img_color.getpixel((w,h)))[0])\n",
    "        Y_true_b.append(rgb_ab(img_color.getpixel((w,h)))[1])\n",
    "  \n",
    "  # Guardar el valor final de MSE de toda la imagen en la respectiva lista\n",
    "  MSE_a.append(mean_squared_error(Y_true_a,Y_pred_a))\n",
    "  MSE_b.append(mean_squared_error(Y_true_b,Y_pred_b))\n",
    "\n",
    "# Sacar el promedio de las listas\n",
    "print(\"MSE promedio por imagen entre color y nuestras predicciones\")\n",
    "print(\"a\", mean(MSE_a))\n",
    "print(\"b\", mean(MSE_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21404,
     "status": "ok",
     "timestamp": 1669622866359,
     "user": {
      "displayName": "Ximena González",
      "userId": "01616957970933617687"
     },
     "user_tz": 480
    },
    "id": "m1Nxh9pQQQiT",
    "outputId": "152f44cb-b688-46a4-fe4d-37ddc290a28b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE promedio por imagen entre color y algoritmo siggraph\n",
      "a 0.09295181503978404\n",
      "b 0.009430649917240436\n"
     ]
    }
   ],
   "source": [
    "# Arreglo que contendrá el MSE de cada imágen\n",
    "MSE_a = []\n",
    "MSE_b = []\n",
    "\n",
    "for i in range(len(images_color)): # Por cada imagen\n",
    "  img_color = Image.open('original/' + images_color[i]) # Abrir imagen a color\n",
    "  img_sigg = Image.open('algorithm_siggraph/' + images_pred[i]) # Abrir predicción\n",
    "\n",
    "  # Se guardan los valores de los pixeles \n",
    "  Y_pred_a = []\n",
    "  Y_pred_b = []\n",
    "  Y_true_a = []\n",
    "  Y_true_b = []\n",
    "\n",
    "  for w in range(img_color.size[0]):\n",
    "    for h in range(img_color.size[1]):\n",
    "      # Por cada pixel en altura y ancho de la imagen\n",
    "        # Regresar el valor a,b del pixel y agregarlo a su respectiva lista entre las imagenes original y la predicción:\n",
    "        Y_pred_a.append(rgb_ab(img_sigg.getpixel((w,h)))[0])\n",
    "        Y_pred_b.append(rgb_ab(img_sigg.getpixel((w,h)))[1])  \n",
    "        Y_true_a.append(rgb_ab(img_color.getpixel((w,h)))[0])\n",
    "        Y_true_b.append(rgb_ab(img_color.getpixel((w,h)))[1])\n",
    "  \n",
    "  # Guardar el valor final de MSE de toda la imagen en la respectiva lista\n",
    "  MSE_a.append(mean_squared_error(Y_true_a,Y_pred_a))\n",
    "  MSE_b.append(mean_squared_error(Y_true_b,Y_pred_b))\n",
    "\n",
    "# Sacar el promedio de las listas\n",
    "print(\"MSE promedio por imagen entre color y algoritmo siggraph\")\n",
    "print(\"a\", mean(MSE_a))\n",
    "print(\"b\", mean(MSE_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29654,
     "status": "ok",
     "timestamp": 1669683037337,
     "user": {
      "displayName": "Ximena González",
      "userId": "01616957970933617687"
     },
     "user_tz": 480
    },
    "id": "3OGxMklmRZHR",
    "outputId": "f0063c43-0593-4ef9-89a5-69bf8e26f0e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE promedio por imagen entre color y escala de grises\n",
      "a 0.29198281505354023\n",
      "b 0.028430336858659706\n"
     ]
    }
   ],
   "source": [
    "# Arreglo que contendrá el MSE de cada imágen\n",
    "MSE_a = []\n",
    "MSE_b = []\n",
    "\n",
    "for i in range(len(images_color)): # Por cada imagen\n",
    "  img_color = Image.open('original/' + images_color[i]) # Abrir imagen a color\n",
    "  img_bw = Image.open('bw/' + images_pred[i]) # Abrir predicción\n",
    "\n",
    "  # Se guardan los valores de los pixeles \n",
    "  Y_pred_a = []\n",
    "  Y_pred_b = []\n",
    "  Y_true_a = []\n",
    "  Y_true_b = []\n",
    "\n",
    "  for w in range(img_color.size[0]):\n",
    "    for h in range(img_color.size[1]):\n",
    "      # Por cada pixel en altura y ancho de la imagen\n",
    "        # Regresar el valor a,b del pixel y agregarlo a su respectiva lista entre las imagenes original y la predicción:\n",
    "        Y_pred_a.append(rgb_ab(img_bw.getpixel((w,h)))[0])\n",
    "        Y_pred_b.append(rgb_ab(img_bw.getpixel((w,h)))[1])  \n",
    "        Y_true_a.append(rgb_ab(img_color.getpixel((w,h)))[0])\n",
    "        Y_true_b.append(rgb_ab(img_color.getpixel((w,h)))[1])\n",
    "  \n",
    "  # Guardar el valor final de MSE de toda la imagen en la respectiva lista\n",
    "  MSE_a.append(mean_squared_error(Y_true_a,Y_pred_a))\n",
    "  MSE_b.append(mean_squared_error(Y_true_b,Y_pred_b))\n",
    "\n",
    "# Sacar el promedio de las listas\n",
    "print(\"MSE promedio por imagen entre color y escala de grises\")\n",
    "print(\"a\", mean(MSE_a))\n",
    "print(\"b\", mean(MSE_b))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP50Le5WezMHFRIuGrs4yHY",
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "05a094b6c9874ee9b3e5da3375f79255": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "300e6a88fa394c1aac3d2dbcb0d91196": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "33b04a17fd5c4bd69523bfa90605ede5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_05a094b6c9874ee9b3e5da3375f79255",
      "placeholder": "​",
      "style": "IPY_MODEL_5e7750a0784c4e439829374c8b2ab92d",
      "value": " 130M/130M [00:02&lt;00:00, 66.2MB/s]"
     }
    },
    "3f5bfdbf55594af8a2ca09371baa9d09": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_84203aa2f56b422d858d499f3b9423f1",
      "max": 136787426,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_300e6a88fa394c1aac3d2dbcb0d91196",
      "value": 136787426
     }
    },
    "472ecf1f6c494e55aa0fe8739555a40b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9665b1654eac4130821c43b878a058c1",
      "placeholder": "​",
      "style": "IPY_MODEL_c3754762a8c24b898af8da17108b3d0a",
      "value": "100%"
     }
    },
    "5e7750a0784c4e439829374c8b2ab92d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "737ee5c5c22c40298bf85c8386df7e68": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "84203aa2f56b422d858d499f3b9423f1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9665b1654eac4130821c43b878a058c1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c3754762a8c24b898af8da17108b3d0a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c75ee4e76d104b13b3d0ae98b6638890": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_472ecf1f6c494e55aa0fe8739555a40b",
       "IPY_MODEL_3f5bfdbf55594af8a2ca09371baa9d09",
       "IPY_MODEL_33b04a17fd5c4bd69523bfa90605ede5"
      ],
      "layout": "IPY_MODEL_737ee5c5c22c40298bf85c8386df7e68"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
